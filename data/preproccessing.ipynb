{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4aff4c17-65aa-4f41-a89e-1457be783566",
   "metadata": {},
   "source": [
    "# Yazan Aakel - 5171606\n",
    "## Data Visualization Course\n",
    "* this notebook is for manipulating the data to produce it in a suitable form for drawing the required charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87cc0cad-e1d4-47c7-8454-14454ed2ffea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.1.2-cp310-cp310-macosx_11_0_arm64.whl (10.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Collecting tzdata>=2022.1\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2,>=1.22.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (1.24.3)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.5/502.5 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires portpicker==1.5.2, which is not installed.\n",
      "google-colab 1.0.0 requires google-auth==2.17.3, but you have google-auth 2.22.0 which is incompatible.\n",
      "google-colab 1.0.0 requires ipykernel==5.5.6, but you have ipykernel 6.26.0 which is incompatible.\n",
      "google-colab 1.0.0 requires ipython==7.34.0, but you have ipython 8.17.2 which is incompatible.\n",
      "google-colab 1.0.0 requires notebook==6.5.5, but you have notebook 7.0.6 which is incompatible.\n",
      "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.1.2 which is incompatible.\n",
      "google-colab 1.0.0 requires tornado==6.3.2, but you have tornado 6.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed pandas-2.1.2 pytz-2023.3.post1 tzdata-2023.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc8d865-db39-4b80-8bb6-0a1cdc249c20",
   "metadata": {},
   "source": [
    "# Assignment 1 - Task 1 - Finding top 10 tree species with Other in each city - used for vertical and horizontal barcharts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78021964-4897-495c-85b2-fd909f838653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def process_data(number_of_top_trees=10):\n",
    "    # Directory where your CSV files are located\n",
    "    data_directory = \"./Desktop/data-vis\"\n",
    "\n",
    "# Create a directory for the output JSON file\n",
    "    output_directory = os.path.join(data_directory, \"output\")\n",
    "    os.makedirs(output_directory, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "# Initialize an empty dictionary to store the aggregated data\n",
    "    aggregated_data = pd.DataFrame(columns=[\"scientific_name\", \"common_name\", \"city\", \"state\", \"height_M\", \"tree_count\"])\n",
    "    aggregated_data['height_M'] = aggregated_data['height_M'].apply(lambda x: x if x > 0 else None)\n",
    "\n",
    "# List all CSV files in the directory\n",
    "    csv_files = [file for file in os.listdir(data_directory) if file.endswith(\".csv\")]\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        print(\"processing .. \" + csv_file)\n",
    "    \n",
    "        # Load the data from the CSV file\n",
    "        data = pd.read_csv(os.path.join(data_directory, csv_file), usecols=['scientific_name', 'city', 'state', 'height_M'])\n",
    "        #data.dropna(how='any', inplace=True)\n",
    "    \n",
    "        df_avg_mean = data.groupby([\"scientific_name\", \"city\", \"state\"])['height_M'].mean().reset_index(name=\"avg_mean\")\n",
    "        # Group the data by a combination of \"city\" and \"scientific_name\" and count the number of trees in each combination\n",
    "        city_tree_count = data.groupby([\"scientific_name\", \"city\", \"state\"]).size().reset_index(name=\"tree_count\")\n",
    "        city_tree_count = city_tree_count.merge(df_avg_mean, on=[\"scientific_name\", \"city\", \"state\"], how=\"left\")\n",
    "        \n",
    "        city_tree_count['avg_mean'] = city_tree_count['avg_mean'].fillna(0)\n",
    "\n",
    "    # Create a dictionary to store city-specific data\n",
    "    #city_data = {}\n",
    "\n",
    "    # Iterate through the sorted data and select the top 10 trees for each city\n",
    "        for city, city_group in city_tree_count.groupby(\"city\"):\n",
    "    \n",
    "            top_trees = city_group.nlargest(number_of_top_trees, \"tree_count\")\n",
    "    \n",
    "            if len(top_trees) < number_of_top_trees:\n",
    "                continue\n",
    "            diff = pd.concat([city_group, top_trees]).drop_duplicates(keep=False)\n",
    "           # print(diff.head(10))\n",
    "            remaining_count = diff[\"tree_count\"].sum()\n",
    "    \n",
    "            remaining_height_avg = diff[\"avg_mean\"].sum()\n",
    "            # Convert int64 to regular Python int for serialization\n",
    "            top_trees[\"tree_count\"] = top_trees[\"tree_count\"].astype(int)\n",
    "            remaining_count = int(remaining_count)\n",
    "    \n",
    "    \n",
    "            #top_trees = top_trees.to_dict(orient=\"records\")\n",
    "            top_trees = pd.concat([top_trees, pd.DataFrame({'scientific_name': \"Other\",\"city\":city, \"state\":city_group['state'],\n",
    "                                                                  \"tree_count\": remaining_count, \n",
    "                                                                \"avg_mean\":remaining_height_avg})], ignore_index=True)\n",
    "    \n",
    "    \n",
    "            aggregated_data = pd.concat([aggregated_data, top_trees], ignore_index=True).drop_duplicates(keep='first')\n",
    "\n",
    "    # Add city-specific data to the aggregated_data dictionary\n",
    "    #aggregated_data.update(city_data)\n",
    "\n",
    "# Sort the aggregated_data dictionary by city names alphabetically\n",
    "#aggregated_data = dict(sorted(aggregated_data.items()))\n",
    "    aggregated_data.sort_values(by=[\"tree_count\"], inplace=True, ascending=False)\n",
    "\n",
    "# Save the aggregated JSON data to a single file in the output directory\n",
    "    output_file = os.path.join(output_directory, \"city_tree_counts_top_\" + str(number_of_top_trees) + \".csv\")\n",
    "    aggregated_data.to_csv(output_file, index=False)\n",
    "\n",
    "    cities = aggregated_data[\"city\"].unique()\n",
    "    print(cities)\n",
    "\n",
    "\n",
    "    cities_output_file = os.path.join(output_directory, \"cities.txt\")\n",
    "\n",
    "    with open(cities_output_file, \"w\") as citiesOutfile:\n",
    "        for item in cities:\n",
    "        # write each item on a new line\n",
    "            citiesOutfile.write(\"%s\\n\" % item)\n",
    "\n",
    "\n",
    "    states = aggregated_data[\"state\"].unique()\n",
    "    print(states)\n",
    "\n",
    "    states_output_file = os.path.join(output_directory, \"states.txt\")\n",
    "\n",
    "    with open(states_output_file, \"w\") as statesOutfile:\n",
    "        for item in states:\n",
    "        # write each item on a new line\n",
    "            statesOutfile.write(\"%s\\n\" % item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2c9c07b-d46b-49a4-92e4-41aeeb631ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing .. Milwaukee_Final_2022-06-18.csv\n",
      "processing .. Anaheim_Final_2022-06-18.csv\n",
      "processing .. Irvine_Final_2022-06-18.csv\n",
      "processing .. RanchoCucamonga_Final_2022-06-18.csv\n",
      "processing .. Arlington_Final_2022-06-18.csv\n",
      "processing .. Rochester_Final_2022-06-18.csv\n",
      "processing .. Miami_Final_2022-06-18.csv\n",
      "processing .. Austin_Final_2022-06-18.csv\n",
      "processing .. Stockton_Final_2022-06-18.csv\n",
      "processing .. Seattle_Final_2022-06-18.csv\n",
      "processing .. LosAngeles_Final_2022-06-18.csv\n",
      "processing .. AuroraCO_Final_2022-06-18.csv\n",
      "processing .. NewYork_Final_2022-06-18.csv\n",
      "processing .. Oakland_Final_2022-06-18.csv\n",
      "processing .. SanFrancisco_Final_2022-06-18.csv\n",
      "processing .. Boston_Final_2022-06-18.csv\n",
      "processing .. Ontario_Final_2022-06-18.csv\n",
      "processing .. GrandRapids_Final_2022-06-18.csv\n",
      "processing .. Baltimore_Final_2022-06-18.csv\n",
      "processing .. Albuquerque_Final_2022-06-18.csv\n",
      "processing .. Greensboro_Final_2022-06-18.csv\n",
      "processing .. OklahomaCity_Final_2022-06-18.csv\n",
      "processing .. HuntingtonBeach_Final_2022-06-18.csv\n",
      "processing .. Fresno_Final_2022-06-18.csv\n",
      "processing .. Orlando_Final_2022-06-18.csv\n",
      "processing .. Nashville_Final_2022-06-18.csv\n",
      "processing .. StLouis_Final_2022-06-18.csv\n",
      "processing .. Tampa_Final_2022-06-18.csv\n",
      "processing .. LasVegas_Final_2022-06-18.csv\n",
      "processing .. Phoenix_Final_2022-06-18.csv\n",
      "processing .. Minneapolis_Final_2022-06-18.csv\n",
      "processing .. Indianapolis_Final_2022-06-18.csv\n",
      "processing .. NewOrleans_Final_2022-06-18.csv\n",
      "processing .. Madison_Final_2022-06-18.csv\n",
      "processing .. Columbus_Final_2022-06-18.csv\n",
      "processing .. Knoxville_Final_2022-06-18.csv\n",
      "processing .. GardenGrove_Final_2022-06-18.csv\n",
      "processing .. Honolulu_Final_2022-06-18.csv\n",
      "processing .. Plano_Final_2022-06-18.csv\n",
      "processing .. Richmond_Final_2022-06-18.csv\n",
      "processing .. Jerseycity_Final_2022-06-18.csv\n",
      "processing .. Detroit_Final_2022-06-18.csv\n",
      "processing .. Portland_Final_2022-06-18.csv\n",
      "processing .. Providence_Final_2022-06-18.csv\n",
      "processing .. SanJose_Final_2022-06-18.csv\n",
      "processing .. Atlanta_Final_2022-06-18.csv\n",
      "processing .. ColoradoSprings_Final_2022-06-18.csv\n",
      "processing .. Pittsburgh_Final_2022-06-18.csv\n",
      "processing .. Louisville_Final_2022-06-18.csv\n",
      "processing .. CapeCoral_Final_2022-06-18.csv\n",
      "processing .. Denver_Final_2022-06-18.csv\n",
      "processing .. Worcester_Final_2022-06-18.csv\n",
      "processing .. OverlandPark_Final_2022-06-18.csv\n",
      "processing .. Houston_Final_2022-06-18.csv\n",
      "processing .. Durham_Final_2022-06-18.csv\n",
      "processing .. SanDiego_Final_2022-06-18.csv\n",
      "processing .. Dallas_Final_2022-06-18.csv\n",
      "processing .. SantaRosa_Final_2022-06-18.csv\n",
      "processing .. DesMoines_Final_2022-06-18.csv\n",
      "processing .. Sacramento_Final_2022-06-18.csv\n",
      "processing .. WashingtonDC_Final_2022-06-18.csv\n",
      "processing .. Buffalo_Final_2022-06-18.csv\n",
      "processing .. SiouxFalls_Final_2022-06-18.csv\n",
      "['Los Angeles' 'New York' 'Denver' 'San Jose' 'Seattle' 'San Francisco'\n",
      " 'Portland' 'Washington DC' 'San Diego' 'Columbus' 'Baltimore' 'Houston'\n",
      " 'Indianapolis' 'Minneapolis' 'Stockton' 'Sacramento' 'St. Louis'\n",
      " 'Buffalo' 'New Orleans' 'Ontario' 'Rancho Cucamonga' 'Anaheim' 'Irvine'\n",
      " 'Sioux Falls' 'Huntington Beach' 'Grand Rapids' 'Louisville' 'Madison'\n",
      " 'Rochester' 'Atlanta' 'Orlando' 'Pittsburgh' 'Aurora' 'Oakland'\n",
      " 'Overland Park' 'Las Vegas' 'Detroit' 'Worcester' 'Cape Coral'\n",
      " 'Providence' 'Garden Grove' 'Arlington' 'Durham' 'Colorado Springs'\n",
      " 'Tampa' 'Plano' 'Knoxville' 'Oklahoma City' 'Honolulu' 'Milwaukee'\n",
      " 'Greensboro' 'New Berlin' 'Watertown' 'Fresno' 'Kailua' 'Newton' 'Dallas'\n",
      " 'Albuquerque' 'Decatur' 'Austin' 'Kaneohe' 'Nashville' 'Waukee'\n",
      " 'Richmond' 'Wauwatosa' 'Pleasant Hill' 'Santa Rosa' 'Dunwoody' 'Glendale'\n",
      " 'Boston' 'Miami' 'West Allis' 'EastPoint' 'Bondurant' 'Dallas Center'\n",
      " 'Coon Rapids' 'Hales Corners' 'Monroe' 'Windsor Heights' 'Earlham'\n",
      " 'Baxter' 'Carlisle' 'South Milwaukee' 'Jersey City' 'Unincorporated'\n",
      " 'Brown Deer' 'Cudahy' 'AvondaleEstates' 'Greenfield' 'Adel' 'Greendale'\n",
      " 'Woodward' 'Phoenix' 'Franklin' 'Stuart' 'SandySprings' 'Prairie City'\n",
      " 'Milo' 'Granger' 'De Soto' 'Adair' 'Guthrie Center' 'Mitchellville'\n",
      " 'Colfax' 'Doraville' 'Panora' 'Polk City' 'Oak Creek' 'Hapeville'\n",
      " 'Bouton' 'Union' 'Sully' 'Dexter' 'CollegePark' 'Redfield' 'Fox Point'\n",
      " 'Kellogg' 'Brookhaven' 'Chamblee' 'Elkhart' 'West Milwaukee' 'Shorewood'\n",
      " 'Marietta' 'Bayard' 'Runnells' 'Van Meter' 'Whitefish Bay'\n",
      " 'CandlerMcAfee' 'Hartford']\n",
      "['California' 'New York' 'Colorado' 'Washington' 'Oregon'\n",
      " 'District of Columbia' 'Ohio' 'Maryland' 'Texas' 'Indiana' 'Minnesota'\n",
      " 'Missouri' 'Louisiana' 'South Dakota' 'Michigan' 'Kentucky' 'Wisconsin'\n",
      " 'Georgia' 'Florida' 'Pennsylvania' 'Kansas' 'Nevada' 'Massachusetts'\n",
      " 'Rhode Island' 'North Carolina' 'Tennessee' 'Oklahoma' 'Hawaii' 'Iowa'\n",
      " 'New Mexico' 'Virginia' 'New Jersey' 'Arizona']\n"
     ]
    }
   ],
   "source": [
    "# processing for tasks that requires showing data for top 10 trees\n",
    "process_data(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "883c8798-45f8-4f3d-a1f2-e1312be8648a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing .. Milwaukee_Final_2022-06-18.csv\n",
      "processing .. Anaheim_Final_2022-06-18.csv\n",
      "processing .. Irvine_Final_2022-06-18.csv\n",
      "processing .. RanchoCucamonga_Final_2022-06-18.csv\n",
      "processing .. Arlington_Final_2022-06-18.csv\n",
      "processing .. Rochester_Final_2022-06-18.csv\n",
      "processing .. Miami_Final_2022-06-18.csv\n",
      "processing .. Austin_Final_2022-06-18.csv\n",
      "processing .. Stockton_Final_2022-06-18.csv\n",
      "processing .. Seattle_Final_2022-06-18.csv\n",
      "processing .. LosAngeles_Final_2022-06-18.csv\n",
      "processing .. AuroraCO_Final_2022-06-18.csv\n",
      "processing .. NewYork_Final_2022-06-18.csv\n",
      "processing .. Oakland_Final_2022-06-18.csv\n",
      "processing .. SanFrancisco_Final_2022-06-18.csv\n",
      "processing .. Boston_Final_2022-06-18.csv\n",
      "processing .. Ontario_Final_2022-06-18.csv\n",
      "processing .. GrandRapids_Final_2022-06-18.csv\n",
      "processing .. Baltimore_Final_2022-06-18.csv\n",
      "processing .. Albuquerque_Final_2022-06-18.csv\n",
      "processing .. Greensboro_Final_2022-06-18.csv\n",
      "processing .. OklahomaCity_Final_2022-06-18.csv\n",
      "processing .. HuntingtonBeach_Final_2022-06-18.csv\n",
      "processing .. Fresno_Final_2022-06-18.csv\n",
      "processing .. Orlando_Final_2022-06-18.csv\n",
      "processing .. Nashville_Final_2022-06-18.csv\n",
      "processing .. StLouis_Final_2022-06-18.csv\n",
      "processing .. Tampa_Final_2022-06-18.csv\n",
      "processing .. LasVegas_Final_2022-06-18.csv\n",
      "processing .. Phoenix_Final_2022-06-18.csv\n",
      "processing .. Minneapolis_Final_2022-06-18.csv\n",
      "processing .. Indianapolis_Final_2022-06-18.csv\n",
      "processing .. NewOrleans_Final_2022-06-18.csv\n",
      "processing .. Madison_Final_2022-06-18.csv\n",
      "processing .. Columbus_Final_2022-06-18.csv\n",
      "processing .. Knoxville_Final_2022-06-18.csv\n",
      "processing .. GardenGrove_Final_2022-06-18.csv\n",
      "processing .. Honolulu_Final_2022-06-18.csv\n",
      "processing .. Plano_Final_2022-06-18.csv\n",
      "processing .. Richmond_Final_2022-06-18.csv\n",
      "processing .. Jerseycity_Final_2022-06-18.csv\n",
      "processing .. Detroit_Final_2022-06-18.csv\n",
      "processing .. Portland_Final_2022-06-18.csv\n",
      "processing .. Providence_Final_2022-06-18.csv\n",
      "processing .. SanJose_Final_2022-06-18.csv\n",
      "processing .. Atlanta_Final_2022-06-18.csv\n",
      "processing .. ColoradoSprings_Final_2022-06-18.csv\n",
      "processing .. Pittsburgh_Final_2022-06-18.csv\n",
      "processing .. Louisville_Final_2022-06-18.csv\n",
      "processing .. CapeCoral_Final_2022-06-18.csv\n",
      "processing .. Denver_Final_2022-06-18.csv\n",
      "processing .. Worcester_Final_2022-06-18.csv\n",
      "processing .. OverlandPark_Final_2022-06-18.csv\n",
      "processing .. Houston_Final_2022-06-18.csv\n",
      "processing .. Durham_Final_2022-06-18.csv\n",
      "processing .. SanDiego_Final_2022-06-18.csv\n",
      "processing .. Dallas_Final_2022-06-18.csv\n",
      "processing .. SantaRosa_Final_2022-06-18.csv\n",
      "processing .. DesMoines_Final_2022-06-18.csv\n",
      "processing .. Sacramento_Final_2022-06-18.csv\n",
      "processing .. WashingtonDC_Final_2022-06-18.csv\n",
      "processing .. Buffalo_Final_2022-06-18.csv\n",
      "processing .. SiouxFalls_Final_2022-06-18.csv\n",
      "['Los Angeles' 'New York' 'Denver' 'San Jose' 'San Diego' 'Portland'\n",
      " 'Seattle' 'San Francisco' 'Washington DC' 'Minneapolis' 'Columbus'\n",
      " 'Houston' 'Baltimore' 'Indianapolis' 'Stockton' 'Sacramento' 'St. Louis'\n",
      " 'Rancho Cucamonga' 'Buffalo' 'New Orleans' 'Ontario' 'Irvine' 'Anaheim'\n",
      " 'Madison' 'Grand Rapids' 'Rochester' 'Huntington Beach' 'Aurora'\n",
      " 'Louisville' 'Atlanta' 'Pittsburgh' 'Sioux Falls' 'Oakland' 'Orlando'\n",
      " 'Las Vegas' 'Overland Park' 'Detroit' 'Providence' 'Cape Coral'\n",
      " 'Garden Grove' 'Plano' 'Tampa' 'Worcester' 'Arlington' 'Colorado Springs'\n",
      " 'Durham' 'Milwaukee' 'Oklahoma City' 'Knoxville' 'Honolulu' 'Greensboro'\n",
      " 'New Berlin' 'Watertown' 'Fresno' 'Kailua' 'Austin' 'Dallas' 'Newton'\n",
      " 'Albuquerque' 'Decatur' 'Kaneohe' 'Nashville' 'Waukee' 'Richmond'\n",
      " 'Wauwatosa' 'Pleasant Hill' 'Glendale' 'Boston' 'Dunwoody' 'West Allis'\n",
      " 'Miami' 'Santa Rosa' 'EastPoint' 'Dallas Center' 'Jersey City'\n",
      " 'Bondurant' 'Coon Rapids' 'Monroe' 'Hales Corners' 'Carlisle'\n",
      " 'Unincorporated' 'South Milwaukee' 'Windsor Heights' 'Adel' 'Cudahy'\n",
      " 'Greenfield' 'AvondaleEstates' 'Woodward' 'Brown Deer' 'Franklin'\n",
      " 'Earlham' 'Greendale' 'Prairie City' 'Baxter' 'Phoenix' 'SandySprings'\n",
      " 'Stuart' 'Adair' 'Milo' 'Granger' 'Colfax' 'Mitchellville' 'Clarkston'\n",
      " 'Hapeville' 'Oak Creek' 'Dexter' 'Fox Point' 'De Soto' 'Redfield' 'Sully'\n",
      " 'Guthrie Center' 'Panora' 'CollegePark' 'Doraville' 'Brookhaven'\n",
      " 'Polk City' 'Union' 'Bouton' 'Shorewood' 'Chamblee' 'Kellogg' 'Elkhart'\n",
      " 'West Milwaukee' 'Whitefish Bay' 'Runnells' 'Scottdale' 'Marietta'\n",
      " 'Bayard' 'Hartford' 'Van Meter' 'Oakland Acres' 'CandlerMcAfee'\n",
      " 'Des Moines']\n",
      "['California' 'New York' 'Colorado' 'Oregon' 'Washington'\n",
      " 'District of Columbia' 'Minnesota' 'Ohio' 'Texas' 'Maryland' 'Indiana'\n",
      " 'Missouri' 'Louisiana' 'Wisconsin' 'Michigan' 'Kentucky' 'Georgia'\n",
      " 'Pennsylvania' 'South Dakota' 'Florida' 'Nevada' 'Kansas' 'Rhode Island'\n",
      " 'Massachusetts' 'North Carolina' 'Oklahoma' 'Tennessee' 'Hawaii' 'Iowa'\n",
      " 'New Mexico' 'Virginia' 'New Jersey' 'Arizona']\n"
     ]
    }
   ],
   "source": [
    "process_data(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bbeea0-dace-47c8-958f-7a2e5e5ed384",
   "metadata": {},
   "source": [
    "# This is for heatmap, eliminating the cities that does not have a certain type of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "803f1fa5-5a75-4956-9eae-5b1280341867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Milwaukee_Final_2022-06-18.csv\n",
      "Processing Anaheim_Final_2022-06-18.csv\n",
      "Processing Irvine_Final_2022-06-18.csv\n",
      "Processing RanchoCucamonga_Final_2022-06-18.csv\n",
      "Processing Arlington_Final_2022-06-18.csv\n",
      "Processing Rochester_Final_2022-06-18.csv\n",
      "Processing Miami_Final_2022-06-18.csv\n",
      "Processing Austin_Final_2022-06-18.csv\n",
      "Processing Stockton_Final_2022-06-18.csv\n",
      "Processing Seattle_Final_2022-06-18.csv\n",
      "Processing LosAngeles_Final_2022-06-18.csv\n",
      "Processing AuroraCO_Final_2022-06-18.csv\n",
      "Processing NewYork_Final_2022-06-18.csv\n",
      "Processing Oakland_Final_2022-06-18.csv\n",
      "Processing SanFrancisco_Final_2022-06-18.csv\n",
      "Processing Boston_Final_2022-06-18.csv\n",
      "Processing Ontario_Final_2022-06-18.csv\n",
      "Processing GrandRapids_Final_2022-06-18.csv\n",
      "Processing Baltimore_Final_2022-06-18.csv\n",
      "Processing Albuquerque_Final_2022-06-18.csv\n",
      "Processing Greensboro_Final_2022-06-18.csv\n",
      "Processing OklahomaCity_Final_2022-06-18.csv\n",
      "Processing HuntingtonBeach_Final_2022-06-18.csv\n",
      "Processing Fresno_Final_2022-06-18.csv\n",
      "Processing Orlando_Final_2022-06-18.csv\n",
      "Processing Nashville_Final_2022-06-18.csv\n",
      "Processing StLouis_Final_2022-06-18.csv\n",
      "Processing Tampa_Final_2022-06-18.csv\n",
      "Processing LasVegas_Final_2022-06-18.csv\n",
      "Processing Phoenix_Final_2022-06-18.csv\n",
      "Processing Minneapolis_Final_2022-06-18.csv\n",
      "Processing Indianapolis_Final_2022-06-18.csv\n",
      "Processing NewOrleans_Final_2022-06-18.csv\n",
      "Processing Madison_Final_2022-06-18.csv\n",
      "Processing Columbus_Final_2022-06-18.csv\n",
      "Processing Knoxville_Final_2022-06-18.csv\n",
      "Processing GardenGrove_Final_2022-06-18.csv\n",
      "Processing Honolulu_Final_2022-06-18.csv\n",
      "Processing Plano_Final_2022-06-18.csv\n",
      "Processing Richmond_Final_2022-06-18.csv\n",
      "Processing Jerseycity_Final_2022-06-18.csv\n",
      "Processing Detroit_Final_2022-06-18.csv\n",
      "Processing Portland_Final_2022-06-18.csv\n",
      "Processing Providence_Final_2022-06-18.csv\n",
      "Processing SanJose_Final_2022-06-18.csv\n",
      "Processing Atlanta_Final_2022-06-18.csv\n",
      "Processing ColoradoSprings_Final_2022-06-18.csv\n",
      "Processing Pittsburgh_Final_2022-06-18.csv\n",
      "Processing Louisville_Final_2022-06-18.csv\n",
      "Processing CapeCoral_Final_2022-06-18.csv\n",
      "Processing Denver_Final_2022-06-18.csv\n",
      "Processing Worcester_Final_2022-06-18.csv\n",
      "Processing OverlandPark_Final_2022-06-18.csv\n",
      "Processing Houston_Final_2022-06-18.csv\n",
      "Processing Durham_Final_2022-06-18.csv\n",
      "Processing SanDiego_Final_2022-06-18.csv\n",
      "Processing Dallas_Final_2022-06-18.csv\n",
      "Processing SantaRosa_Final_2022-06-18.csv\n",
      "Processing DesMoines_Final_2022-06-18.csv\n",
      "Processing Sacramento_Final_2022-06-18.csv\n",
      "Processing WashingtonDC_Final_2022-06-18.csv\n",
      "Processing Buffalo_Final_2022-06-18.csv\n",
      "Processing SiouxFalls_Final_2022-06-18.csv\n",
      "Filtered CSV file saved: ./Desktop/data-vis/output/tree_occurrences_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory where your CSV files are located\n",
    "data_directory = \"./Desktop/data-vis\"\n",
    "\n",
    "# Create a directory for the output CSV file\n",
    "output_directory = os.path.join(data_directory, \"output\")\n",
    "os.makedirs(output_directory, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "# Initialize an empty dictionary to store the aggregated data\n",
    "aggregated_data = {}\n",
    "\n",
    "# List all CSV files in the directory\n",
    "csv_files = [file for file in os.listdir(data_directory) if file.endswith(\".csv\")]\n",
    "\n",
    "# Define the number of top tree species to consider\n",
    "top_tree_count = 5\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    print(\"Processing \" + csv_file)\n",
    "\n",
    "    # Load the data from the CSV file\n",
    "    data = pd.read_csv(os.path.join(data_directory, csv_file), usecols=['state', 'city', 'common_name', 'scientific_name'])\n",
    "\n",
    "    # Group the data by state, city, and common_name, and count the number of trees in each combination\n",
    "    city_tree_count = data.groupby(['state', 'city', 'scientific_name']).size().reset_index(name=\"tree_count\")\n",
    "\n",
    "    # Sort the data in descending order based on tree_count\n",
    "    sorted_city_tree_count = city_tree_count.sort_values(by=['state', 'city', 'tree_count'], ascending=[True, True, False])\n",
    "\n",
    "    # Create a dictionary to store the top tree occurrences for each city\n",
    "    city_data = {}\n",
    "\n",
    "    for (state, city), group in sorted_city_tree_count.groupby(['state', 'city']):\n",
    "        top_trees = group.head(top_tree_count)\n",
    "        diff = pd.concat([group, top_trees]).drop_duplicates(keep=False)\n",
    "        remaining_count = diff[\"tree_count\"].sum()\n",
    "\n",
    "        \n",
    "        top_trees = pd.concat([top_trees, pd.DataFrame({\"state\": group['state'], \"city\": city, 'scientific_name': \"Other\",\n",
    "                                                       \"tree_count\": remaining_count})]).drop_duplicates(keep='last')\n",
    "\n",
    "        tree_counts = top_trees['tree_count'].tolist()\n",
    "        city_data[(state, city)] = tree_counts\n",
    "\n",
    "    # Add the city-specific data to the aggregated_data dictionary\n",
    "    aggregated_data.update(city_data)\n",
    "\n",
    "# Create a list to store the CSV data\n",
    "csv_data = []\n",
    "\n",
    "# Define column names for the CSV\n",
    "column_names = ['city', 'state', 'scientific_name', 'tree_count']\n",
    "\n",
    "# Iterate through the aggregated data and format it for CSV\n",
    "for (state, city), tree_counts in aggregated_data.items():\n",
    "    for scientific_name, tree_count in zip(top_trees['scientific_name'], tree_counts):\n",
    "        csv_data.append([city, state, scientific_name, tree_count])\n",
    "\n",
    "# Create a DataFrame from the CSV data\n",
    "csv_df = pd.DataFrame(csv_data, columns=column_names)\n",
    "\n",
    "# Filter cities that have at least one of each of the top 5 species\n",
    "filtered_df = csv_df.groupby(['city', 'state']).filter(lambda x: x['scientific_name'].nunique() >= top_tree_count)\n",
    "\n",
    "# Save the aggregated data to a CSV file\n",
    "output_file = os.path.join(output_directory, \"city_tree_counts_top_5.csv\")\n",
    "filtered_df.to_csv(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e940a7e2-229b-4875-a2ff-7b1f5763bba9",
   "metadata": {},
   "source": [
    "# For Stacked Barcharts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b59577a6-a113-48dd-9297-135385fa4459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Milwaukee_Final_2022-06-18.csv\n",
      "Processing Anaheim_Final_2022-06-18.csv\n",
      "Processing Irvine_Final_2022-06-18.csv\n",
      "Processing RanchoCucamonga_Final_2022-06-18.csv\n",
      "Processing Arlington_Final_2022-06-18.csv\n",
      "Processing Rochester_Final_2022-06-18.csv\n",
      "Processing Miami_Final_2022-06-18.csv\n",
      "Processing Austin_Final_2022-06-18.csv\n",
      "Processing Stockton_Final_2022-06-18.csv\n",
      "Processing Seattle_Final_2022-06-18.csv\n",
      "Processing LosAngeles_Final_2022-06-18.csv\n",
      "Processing AuroraCO_Final_2022-06-18.csv\n",
      "Processing NewYork_Final_2022-06-18.csv\n",
      "Processing Oakland_Final_2022-06-18.csv\n",
      "Processing SanFrancisco_Final_2022-06-18.csv\n",
      "Processing Boston_Final_2022-06-18.csv\n",
      "Processing Ontario_Final_2022-06-18.csv\n",
      "Processing GrandRapids_Final_2022-06-18.csv\n",
      "Processing Baltimore_Final_2022-06-18.csv\n",
      "Processing Albuquerque_Final_2022-06-18.csv\n",
      "Processing Greensboro_Final_2022-06-18.csv\n",
      "Processing OklahomaCity_Final_2022-06-18.csv\n",
      "Processing HuntingtonBeach_Final_2022-06-18.csv\n",
      "Processing Fresno_Final_2022-06-18.csv\n",
      "Processing Orlando_Final_2022-06-18.csv\n",
      "Processing Nashville_Final_2022-06-18.csv\n",
      "Processing StLouis_Final_2022-06-18.csv\n",
      "Processing Tampa_Final_2022-06-18.csv\n",
      "Processing LasVegas_Final_2022-06-18.csv\n",
      "Processing Phoenix_Final_2022-06-18.csv\n",
      "Processing Minneapolis_Final_2022-06-18.csv\n",
      "Processing Indianapolis_Final_2022-06-18.csv\n",
      "Processing NewOrleans_Final_2022-06-18.csv\n",
      "Processing Madison_Final_2022-06-18.csv\n",
      "Processing Columbus_Final_2022-06-18.csv\n",
      "Processing Knoxville_Final_2022-06-18.csv\n",
      "Processing GardenGrove_Final_2022-06-18.csv\n",
      "Processing Honolulu_Final_2022-06-18.csv\n",
      "Processing Plano_Final_2022-06-18.csv\n",
      "Processing Richmond_Final_2022-06-18.csv\n",
      "Processing Jerseycity_Final_2022-06-18.csv\n",
      "Processing Detroit_Final_2022-06-18.csv\n",
      "Processing Portland_Final_2022-06-18.csv\n",
      "Processing Providence_Final_2022-06-18.csv\n",
      "Processing SanJose_Final_2022-06-18.csv\n",
      "Processing Atlanta_Final_2022-06-18.csv\n",
      "Processing ColoradoSprings_Final_2022-06-18.csv\n",
      "Processing Pittsburgh_Final_2022-06-18.csv\n",
      "Processing Louisville_Final_2022-06-18.csv\n",
      "Processing CapeCoral_Final_2022-06-18.csv\n",
      "Processing Denver_Final_2022-06-18.csv\n",
      "Processing Worcester_Final_2022-06-18.csv\n",
      "Processing OverlandPark_Final_2022-06-18.csv\n",
      "Processing Houston_Final_2022-06-18.csv\n",
      "Processing Durham_Final_2022-06-18.csv\n",
      "Processing SanDiego_Final_2022-06-18.csv\n",
      "Processing Dallas_Final_2022-06-18.csv\n",
      "Processing SantaRosa_Final_2022-06-18.csv\n",
      "Processing DesMoines_Final_2022-06-18.csv\n",
      "Processing Sacramento_Final_2022-06-18.csv\n",
      "Processing WashingtonDC_Final_2022-06-18.csv\n",
      "Processing Buffalo_Final_2022-06-18.csv\n",
      "Processing SiouxFalls_Final_2022-06-18.csv\n",
      "CSV file saved: ./Desktop/data-vis/output/tree_occurrences.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory where your CSV files are located\n",
    "data_directory = \"./Desktop/data-vis\"\n",
    "\n",
    "# Create a directory for the output CSV file\n",
    "output_directory = os.path.join(data_directory, \"output\")\n",
    "os.makedirs(output_directory, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "# Initialize an empty dictionary to store the aggregated data\n",
    "aggregated_data = {}\n",
    "\n",
    "# List all CSV files in the directory\n",
    "csv_files = [file for file in os.listdir(data_directory) if file.endswith(\".csv\")]\n",
    "\n",
    "# Define the number of top tree species to consider\n",
    "top_tree_count = 5\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    print(\"Processing \" + csv_file)\n",
    "\n",
    "    # Load the data from the CSV file\n",
    "    data = pd.read_csv(os.path.join(data_directory, csv_file), usecols=['state', 'city', 'common_name', 'scientific_name'])\n",
    "\n",
    "    # Group the data by state, city, and common_name, and count the number of trees in each combination\n",
    "    city_tree_count = data.groupby(['state', 'city', 'scientific_name']).size().reset_index(name=\"tree_count\")\n",
    "\n",
    "    # Sort the data in descending order based on tree_count\n",
    "    sorted_city_tree_count = city_tree_count.sort_values(by=['state', 'city', 'tree_count'], ascending=[True, True, False])\n",
    "\n",
    "    # Create a dictionary to store the top tree occurrences for each city\n",
    "    city_data = {}\n",
    "\n",
    "    for (state, city), group in sorted_city_tree_count.groupby(['state', 'city']):\n",
    "        top_trees = group.head(top_tree_count)\n",
    "        diff = pd.concat([group, top_trees]).drop_duplicates(keep=False)\n",
    "        remaining_count = diff[\"tree_count\"].sum()\n",
    "       \n",
    "        top_trees = pd.concat([top_trees, pd.DataFrame({\"state\":group['state'], \"city\":city, 'scientific_name': \"Other\",\n",
    "                                                              \"tree_count\": remaining_count})]).drop_duplicates(keep='last')\n",
    "\n",
    "        tree_counts = top_trees['tree_count'].tolist()\n",
    "        city_data[(state, city)] = tree_counts\n",
    "\n",
    "    # Add the city-specific data to the aggregated_data dictionary\n",
    "    aggregated_data.update(city_data)\n",
    "# Create a list to store the CSV data\n",
    "csv_data = []\n",
    "\n",
    "# Define column names for the CSV\n",
    "column_names = ['state', 'city'] + [f'{row[\"scientific_name\"]}' for index, row in top_trees.iterrows()]\n",
    "\n",
    "# Iterate through the aggregated data and format it for CSV\n",
    "for (state, city), tree_counts in aggregated_data.items():\n",
    "    csv_row = [state, city] + tree_counts\n",
    "    csv_data.append(csv_row)\n",
    "\n",
    "# Create a DataFrame from the CSV data\n",
    "csv_df = pd.DataFrame(csv_data, columns= column_names)\n",
    "\n",
    "# Save the aggregated data to a CSV file\n",
    "output_file = os.path.join(output_directory, \"tree_occurrences_with_city.csv\")\n",
    "csv_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"CSV file saved:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a99b237-1215-49ac-b0b0-7d8cc2bcd232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Milwaukee_Final_2022-06-18.csv\n",
      "Processing Anaheim_Final_2022-06-18.csv\n",
      "Processing Irvine_Final_2022-06-18.csv\n",
      "Processing RanchoCucamonga_Final_2022-06-18.csv\n",
      "Processing Arlington_Final_2022-06-18.csv\n",
      "Processing Rochester_Final_2022-06-18.csv\n",
      "Processing Miami_Final_2022-06-18.csv\n",
      "Processing Austin_Final_2022-06-18.csv\n",
      "Processing Stockton_Final_2022-06-18.csv\n",
      "Processing Seattle_Final_2022-06-18.csv\n",
      "Processing LosAngeles_Final_2022-06-18.csv\n",
      "Processing AuroraCO_Final_2022-06-18.csv\n",
      "Processing NewYork_Final_2022-06-18.csv\n",
      "Processing Oakland_Final_2022-06-18.csv\n",
      "Processing SanFrancisco_Final_2022-06-18.csv\n",
      "Processing Boston_Final_2022-06-18.csv\n",
      "Processing Ontario_Final_2022-06-18.csv\n",
      "Processing GrandRapids_Final_2022-06-18.csv\n",
      "Processing Baltimore_Final_2022-06-18.csv\n",
      "Processing Albuquerque_Final_2022-06-18.csv\n",
      "Processing Greensboro_Final_2022-06-18.csv\n",
      "Processing OklahomaCity_Final_2022-06-18.csv\n",
      "Processing HuntingtonBeach_Final_2022-06-18.csv\n",
      "Processing Fresno_Final_2022-06-18.csv\n",
      "Processing Orlando_Final_2022-06-18.csv\n",
      "Processing Nashville_Final_2022-06-18.csv\n",
      "Processing StLouis_Final_2022-06-18.csv\n",
      "Processing Tampa_Final_2022-06-18.csv\n",
      "Processing LasVegas_Final_2022-06-18.csv\n",
      "Processing Phoenix_Final_2022-06-18.csv\n",
      "Processing Minneapolis_Final_2022-06-18.csv\n",
      "Processing Indianapolis_Final_2022-06-18.csv\n",
      "Processing NewOrleans_Final_2022-06-18.csv\n",
      "Processing Madison_Final_2022-06-18.csv\n",
      "Processing Columbus_Final_2022-06-18.csv\n",
      "Processing Knoxville_Final_2022-06-18.csv\n",
      "Processing GardenGrove_Final_2022-06-18.csv\n",
      "Processing Honolulu_Final_2022-06-18.csv\n",
      "Processing Plano_Final_2022-06-18.csv\n",
      "Processing Richmond_Final_2022-06-18.csv\n",
      "Processing Jerseycity_Final_2022-06-18.csv\n",
      "Processing Detroit_Final_2022-06-18.csv\n",
      "Processing Portland_Final_2022-06-18.csv\n",
      "Processing Providence_Final_2022-06-18.csv\n",
      "Processing SanJose_Final_2022-06-18.csv\n",
      "Processing Atlanta_Final_2022-06-18.csv\n",
      "Processing ColoradoSprings_Final_2022-06-18.csv\n",
      "Processing Pittsburgh_Final_2022-06-18.csv\n",
      "Processing Louisville_Final_2022-06-18.csv\n",
      "Processing CapeCoral_Final_2022-06-18.csv\n",
      "Processing Denver_Final_2022-06-18.csv\n",
      "Processing Worcester_Final_2022-06-18.csv\n",
      "Processing OverlandPark_Final_2022-06-18.csv\n",
      "Processing Houston_Final_2022-06-18.csv\n",
      "Processing Durham_Final_2022-06-18.csv\n",
      "Processing SanDiego_Final_2022-06-18.csv\n",
      "Processing Dallas_Final_2022-06-18.csv\n",
      "Processing SantaRosa_Final_2022-06-18.csv\n",
      "Processing DesMoines_Final_2022-06-18.csv\n",
      "Processing Sacramento_Final_2022-06-18.csv\n",
      "Processing WashingtonDC_Final_2022-06-18.csv\n",
      "Processing Buffalo_Final_2022-06-18.csv\n",
      "Processing SiouxFalls_Final_2022-06-18.csv\n",
      "CSV file saved: ./Desktop/data-vis/output/sankey_data.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory where your CSV files are located\n",
    "data_directory = \"./Desktop/data-vis\"\n",
    "\n",
    "# Create a directory for the output CSV file\n",
    "output_directory = os.path.join(data_directory, \"output\")\n",
    "os.makedirs(output_directory, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "# Initialize an empty DataFrame to store the Sankey data\n",
    "sankey_df = pd.DataFrame(columns=['state', 'city', 'scientific_name', 'count'])\n",
    "\n",
    "# List all CSV files in the directory\n",
    "csv_files = [file for file in os.listdir(data_directory) if file.endswith(\".csv\")]\n",
    "\n",
    "# Define the number of top tree species to consider\n",
    "top_tree_count = 5\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    print(\"Processing \" + csv_file)\n",
    "\n",
    "    # Load the data from the CSV file\n",
    "    data = pd.read_csv(os.path.join(data_directory, csv_file), usecols=['state', 'city', 'scientific_name', 'scientific_name'])\n",
    "\n",
    "    # Group the data by state, city, and common_name, and count the number of trees in each combination\n",
    "    city_tree_count = data.groupby(['state', 'city', 'scientific_name']).size().reset_index(name=\"count\")\n",
    "\n",
    "    # Sort the data in descending order based on count\n",
    "    sorted_city_tree_count = city_tree_count.sort_values(by=['state', 'city', 'count'], ascending=[True, True, False])\n",
    "\n",
    "    # Create a dictionary to store the top tree occurrences for each city\n",
    "    city_data = {}\n",
    "\n",
    "    for (state, city), group in sorted_city_tree_count.groupby(['state', 'city']):\n",
    "        top_trees = group.head(top_tree_count)\n",
    "        \n",
    "        # Append the data to the Sankey DataFrame\n",
    "        sankey_df = pd.concat([sankey_df, top_trees[['state', 'city', 'scientific_name', 'count']]])\n",
    "\n",
    "# Save the Sankey DataFrame to a CSV file\n",
    "output_file = os.path.join(output_directory, \"sankey_data.csv\")\n",
    "sankey_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"CSV file saved:\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38ec7b54-cfa9-4fca-9167-7548f83cf412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.8\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1542750d-5e24-402a-82f4-f0d5c0929e44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
